The datapoints provided represent a very noisy measurement of the true function f.
Therefore, we obviously cannot reproduce this function with such data using machine learning (but we can
still approximate it with relatively high accuracy). The more data we have, the higher the accuracy our model can
achieve. In this case, we have a very limited dataset, so the best possible model accuracy is also limited to some extent.
For this model, we used a KRR-model with a training set consisting of 80% of the data and 5-fold cross validation.

Ideas for improvement:
1. Change the size of the training set. Try building the model with maybe a 70-30, 75-25, 80-20, 85-15 and a 90-10
train-test set split. This could yield better results, especially in this context where we have a small dataset.
2. For every possible train-test-split try 10-fold cross validation. More folds means better estimate of the true 
error but also more computational expenses. Nevertheless, in this case (small dataset) computation shouldn't be a problem.